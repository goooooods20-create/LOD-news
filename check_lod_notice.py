import os, re, json, textwrap
import requests
from bs4 import BeautifulSoup

LIST_URL = "https://lod.nexon.com/news/notice"
BASE = "https://lod.nexon.com"
WEBHOOK = os.environ["DISCORD_WEBHOOK_URL"]
STATE_FILE = "state.json"

UA = {"User-Agent": "Mozilla/5.0 (compatible; LODNoticeBot/1.0)"}

def load_state():
    try:
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return {"last_id": None}

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def soup_from(url: str) -> BeautifulSoup:
    r = requests.get(url, headers=UA, timeout=20)
    r.raise_for_status()
    return BeautifulSoup(r.text, "html.parser")

def get_latest_post_id_and_url():
    soup = soup_from(LIST_URL)
    # ëª©ë¡ì—ì„œ /News/notice/{id} í˜•íƒœ ë§í¬ê°€ ì‹¤ì œë¡œ ì¡´ì¬ :contentReference[oaicite:6]{index=6}
    a = soup.select_one('a[href^="/News/notice/"], a[href^="/news/notice/"]')
    if not a:
        raise RuntimeError("ëª©ë¡ì—ì„œ ê³µì§€ ë§í¬ë¥¼ ëª» ì°¾ìŒ(í˜ì´ì§€ êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥).")
    href = a.get("href", "")
    m = re.search(r"/[Nn]ews/notice/(\d+)", href)
    if not m:
        raise RuntimeError(f"ê³µì§€ ID íŒŒì‹± ì‹¤íŒ¨: {href}")
    post_id = m.group(1)
    url = href if href.startswith("http") else BASE + href
    return post_id, url

def extract_main_text_and_images(detail_url: str):
    soup = soup_from(detail_url)

    # ìŠ¤í¬ë¦½íŠ¸/ìŠ¤íƒ€ì¼ ì œê±°
    for t in soup(["script", "style", "noscript"]):
        t.decompose()

    # ì œëª© í›„ë³´: h1/h2/h3 ì¤‘ ì œì¼ ê·¸ëŸ´ë“¯í•œ ê±°
    title = None
    for tag in ["h1", "h2", "h3"]:
        h = soup.find(tag)
        if h and h.get_text(strip=True):
            title = h.get_text(" ", strip=True)
            break
    if not title:
        title = soup.title.get_text(" ", strip=True) if soup.title else "ì–´ë‘ ì˜ì „ì„¤ ê³µì§€"

    # ë³¸ë¬¸ í›„ë³´: div/section/main ì¤‘ â€œí…ìŠ¤íŠ¸ê°€ ê°€ì¥ ê¸´â€ ë¸”ë¡ì„ ë³¸ë¬¸ìœ¼ë¡œ ê°„ì£¼ (êµ¬ì¡° ë³€ê²½ì— ë¹„êµì  ê°•í•¨)
    candidates = soup.find_all(["main", "section", "div"], limit=5000)
    best = None
    best_len = 0
    for c in candidates:
        txt = c.get_text("\n", strip=True)
        # ë„ˆë¬´ ì§§ì€ ê±´ ì œì™¸
        if len(txt) > best_len and len(txt) >= 200:
            best = c
            best_len = len(txt)

    if not best:
        best = soup.body or soup

    body_text = best.get_text("\n", strip=True)

    # ì´ë¯¸ì§€ ë§í¬ ì¶”ì¶œ(ë³¸ë¬¸ ë¸”ë¡ ì•ˆì˜ img)
    imgs = []
    for img in best.find_all("img"):
        src = img.get("src")
        if not src:
            continue
        if src.startswith("//"):
            src = "https:" + src
        elif src.startswith("/"):
            src = BASE + src
        imgs.append(src)
    # ì¤‘ë³µ ì œê±°
    imgs = list(dict.fromkeys(imgs))

    return title, body_text, imgs

def post_to_discord(messages):
    # ë””ìŠ¤ì½”ë“œ content 2000ì ì œí•œ ë•Œë¬¸ì— ìª¼ê°¬ :contentReference[oaicite:7]{index=7}
    for msg in messages:
        r = requests.post(WEBHOOK, json={"content": msg}, timeout=20)
        r.raise_for_status()

def chunk_text(text: str, chunk_size: int = 1800):
    # ì¤„ë°”ê¿ˆì´ ì—†ê±°ë‚˜ í•œ ì¤„ì´ ë„ˆë¬´ ê¸¸ì–´ë„ ë¬´ì¡°ê±´ ê¸€ììˆ˜ë¡œ ì˜ë¼ì„œ 2000ì ì œí•œì„ í”¼í•¨
    text = (text or "").strip()
    if not text:
        return []

    chunks = []
    i = 0
    n = len(text)
    while i < n:
        chunks.append(text[i:i+chunk_size])
        i += chunk_size
    return chunks

def build_messages(title, detail_url, body_text, imgs):
    header = f"ğŸ“¢ **{title}**\n<{detail_url}>"
    messages = [header]

    # ë³¸ë¬¸ì€ ì—¬ëŸ¬ ë©”ì‹œì§€ë¡œ ë¶„í• 
    for part in chunk_text(body_text, 1800):
        messages.append(part)

    # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ì— ë§í¬ë¡œ ì¶”ê°€
    if imgs:
        img_block = "**ì´ë¯¸ì§€**\n" + "\n".join(imgs)
        for part in chunk_text(img_block, 1800):
            messages.append(part)

    return messages

def main():
    state = load_state()
    post_id, detail_url = get_latest_post_id_and_url()

    if state["last_id"] == post_id:
        return

    title, body_text, imgs = extract_main_text_and_images(detail_url)
    messages = build_messages(title, detail_url, body_text, imgs)

    # ì²« ì‹¤í–‰ì€ ê³¼ê±° ê³µì§€ë¡œ ë„ë°° ë°©ì§€: ì „ì†¡ ì—†ì´ last_idë§Œ ì €ì¥
    post_to_discord(messages)

    state["last_id"] = post_id
    save_state(state)

if __name__ == "__main__":
    main()
